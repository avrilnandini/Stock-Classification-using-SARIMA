# -*- coding: utf-8 -*-
"""SARIMA_RELIANCE1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UboBbqA_w1K_C66Sx5tg_oiitVuaPprH
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn import metrics
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from datetime import date
from datetime import datetime
import yfinance as yf
from statsmodels.tsa.seasonal import seasonal_decompose as sd
from pylab import rcParams

start_date = datetime(2014,1,1)
end_date = datetime(2019,1,1)

df1 = yf.download('RELIANCE.NS', start=start_date, end=end_date)
df1.head()

df1.info()

df1.head()

df1.insert(0, "Date", df1.index, True)
df1.reset_index(drop=True, inplace=True)
df1.info()

df1.head()

df1 = df1[['Date','Close']]
df1.head()

#plot the data
import plotly.express as px
fig = px.line(df1, x='Date', y='Close', title='Reliance Stock Price')
fig.show()

df1.describe()

#checking for stationarity
from statsmodels.tsa.stattools import adfuller
def check_stationarity(df1):
    result = adfuller(df1)
    print('ADF Statistics: %f' % result[0])
    print('p-value: %f' % result[1])
    if result[1] <= 0.05:
      print("Reject the null hypoothesis. Data is stationary")
    else:
      print("Fail to reject null hypothesis.Data is not stationary");

check_stationarity(df1['Close'])

# decompose data to see trend,seasonality and noise
from statsmodels.tsa.seasonal import seasonal_decompose
decompose = seasonal_decompose(df1['Close'], model='additive', period=365)
decompose.plot()

# Assuming you have a DataFrame named 'df1'
df1['Close_diff'] = df1['Close'].diff()
print(df1['Close_diff'].isnull().sum())

df1 = df1.dropna(subset=['Close_diff'])

check_stationarity(df1['Close_diff'])

# decompose data to see trend,seasonality and noise
from statsmodels.tsa.seasonal import seasonal_decompose
decompose = seasonal_decompose(df1['Close_diff'], model='additive', period=365)
decompose.plot()
#d=1

#fnding q value
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
pd.plotting.autocorrelation_plot(df1['Close'])

plot_acf(df1['Close'], alpha=0.05, lags=50)

from statsmodels.tsa.stattools import acf,pacf
x_acf = pd.DataFrame(acf(df1['Close']))
print(x_acf)
#p=17

#finding q
from statsmodels.tsa.stattools import acf,pacf
plot_pacf(df1['Close'], lags=30, alpha=0.05)
#q=2

p=2
d=1
q=2

! pip install pmdarima
import warnings
warnings.filterwarnings('ignore')
from pmdarima.arima import auto_arima

model = auto_arima(df1['Close'], start_p=10, start_q=2, max_p=17, max_q=4, m=12, start_P=0, seasonal=True, d=1, D=1, trace=True, error_action='ignore',supress_warnings=True)

print(model.summary())

import statsmodels.api as sm
import warnings

p,d,q=1,1,0
model = sm.tsa.statespace.SARIMAX(df1['Close'],
                                  order=(p,d,q),
                                  seasonal_order=(2,1,0,12))
model = model.fit()
print(model.summary())

forecast = model.predict(n_periods=30)
#print(forecast)

import plotly.express as px

# Create a new DataFrame to store the predicted values
forecast_df = df1.copy()
forecast_df['Predicted'] = forecast

#ploting data
fig = px.line(forecast_df, x='Date', y=['Close', 'Predicted'], title='Reliance Closing Price')
fig.show()

#predictions = model.predict(start=len(df1['Close']-2), end=len(df1['Close'])+1)
df1.info()

df1.tail()

import pandas as pd
import numpy as np

# Create a new DataFrame to store predictions
df2 = df1.copy()

# Number of days to forecast
forecast_days = 15

for _ in range(forecast_days):
    # Predict the next value
    prediction = model.predict(start=len(df2), end=len(df2))

    # Add the prediction and new date to the DataFrame
    last_date = df2['Date'].iloc[-1]
    new_date = last_date + np.timedelta64(1, 'D')

    # Create a new row DataFrame with the forecasted date and prediction
    new_row = pd.DataFrame({'Date': [new_date], 'Close': prediction})

    # Concatenate the new row to df2
    df2 = pd.concat([df2, new_row], ignore_index=True)

# Print the predicted values for the next 15 days
print(df2.tail(forecast_days))

n=len(df1)

import plotly.express as px

# Create a line plot using Plotly Express
fig = px.line(df1, x='Date', y='Close', title='Reliance Closing Price')

# Create a new trace for the predicted closing prices with dashed line style and different color
predicted_trace = px.line(df2.iloc[n:], x='Date', y='Close', title='Predicted Closing Price')
predicted_trace.update_traces(line_dash='dash', line_color='red')  # Adjust color here

# Add the predicted trace to the figure
fig.add_trace(predicted_trace.data[0])

fig.show()



start_date1 = datetime(2019,1,1)
end_date1 = datetime(2019,1,15)

df3 = yf.download('RELIANCE.NS', start=start_date1, end=end_date1)
df3.head()

df3.insert(0, 'Date', df3.index, True)
df3.reset_index(drop=True, inplace=True)
df3.info()

df3 = df3[['Date','Close']]
df3.head()

#plot the data
import plotly.express as px
fig = px.line(df3, x='Date', y='Close', title='Reliance Stock Price')
fig.show()

import plotly.express as px

# Filter the DataFrame for the desired date range
#predicted stock closing price
start_date = '2019-01-01'
end_date = '2019-01-15'
filtered_df = df2[(df2['Date'] >= start_date) & (df2['Date'] <= end_date)]

# Plot the filtered data
fig = px.line(filtered_df, x='Date', y='Close', title='Reliance Stock Price from 2019-01-01 to 2019-01-15')
fig.show()

import plotly.express as px

# Filter the DataFrame for the desired date range
start_date = '2019-01-01'
end_date = '2019-01-15'
filtered_df2 = df2[(df2['Date'] >= start_date) & (df2['Date'] <= end_date)]
filtered_df3 = df3[(df3['Date'] >= start_date) & (df3['Date'] <= end_date)]

# Merge the dataframes using an inner join on 'Date'
merged_df = filtered_df3.merge(filtered_df2, on='Date', how='inner', suffixes=('_df3', '_df2'))

# Create a line plot for the merged dataframe
fig = px.line(merged_df, x='Date', y=['Close_df3', 'Close_df2'], title='Reliance Stock Price from 2019-01-01 to 2019-01-15')
fig.show()

#close_df3 original
#close_df2 predicted

start_date2 = datetime(2014,1,1)
end_date2 = datetime(2019,1,15)

df4 = yf.download('RELIANCE.NS', start=start_date2, end=end_date2)
df4.head()
#df4 from 2014 to 2019-01-15

df4.insert(0, 'Date', df4.index, True)
df4.reset_index(drop=True, inplace=True)
df4.info()

df4 = df4[['Date','Close']]
df4.head()



import plotly.subplots as sp
import plotly.graph_objects as go

forecast_df = df1.copy()
forecast_df['Predicted'] = forecast

# Filter the DataFrame for the desired date range
start_date = '2019-01-01'
end_date = '2019-01-15'
filtered_df3 = df3[(df3['Date'] >= start_date) & (df3['Date'] <= end_date)]

original = df4['Close']

# Create a subplot with two rows and one column
fig = sp.make_subplots(rows=2, cols=1, shared_xaxes=True)

# Add trace for the predicted closing prices
fig.add_trace(go.Scatter(x=forecast_df['Date'], y=forecast_df['Predicted'], mode='lines', name='Predicted Closing Price'), row=1, col=1)

# Add trace for the filtered original closing prices
fig.add_trace(go.Scatter(x=filtered_df3['Date'], y=filtered_df3['Close'], mode='lines', name='Filtered Original Closing Price'), row=1, col=1)

# Add trace for the original closing prices
fig.add_trace(go.Scatter(x=original.index, y=original, mode='lines', name='Original Closing Price'), row=2, col=1)

# Update layout with titles and labels
fig.update_layout(title='Reliance Stock Price from 2019-01-01 to 2019-01-15',
                  xaxis_title='Date',
                  yaxis_title='Closing Price')

fig.show()



